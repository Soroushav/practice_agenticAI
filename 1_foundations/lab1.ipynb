{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "349ea779",
   "metadata": {},
   "source": [
    "### Challenge between different AI models!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6e39ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee31764",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "openai = OpenAI()\n",
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "gemini = OpenAI(api_key=gemini_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a6f4ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.5,\n",
    "    max_tokens=100,\n",
    ")\n",
    "\n",
    "output = response.choices[0].message.content\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(output))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6d6cee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! As an AI, I don't experience feelings or states of being in the way humans do, but I'm fully operational and ready to assist you. Thank you for asking!\n",
       "\n",
       "How are you doing today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]\n",
    "\n",
    "response = gemini.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "output = response.choices[0].message.content\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "969ba747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello. I'm just a language model, so I don't have feelings or emotions like humans do, but I'm functioning properly and ready to assist you with any questions or topics you'd like to discuss. How about you? How's your day going so far?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]\n",
    "\n",
    "response = groq.chat.completions.create(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "output = response.choices[0].message.content\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e2954",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "    Goal: Create ONE challenging, high-discrimination question to compare AI models. The question must require deep reasoning, not trivia, and should be answerable without browsing.\n",
    "\n",
    "Domain: [pick one:logic, planning, science, law-ish reasoning, creative constraints, etc.]\n",
    "Difficulty target: hard for general LLMs, solvable by top models with careful thinking.\n",
    "Constraints:\n",
    "\t1.\tThe question must be self-contained.\n",
    "\t2.\tIt should have a clear, checkable “ground truth” or at least an objectively gradable standard.\n",
    "\t3.\tIt should include at least 2 traps that catch shallow pattern-matching (e.g., misleading wording, hidden constraints, edge cases).\n",
    "\t4.\tIt must be possible to score answers on reasoning quality, not just final output.\n",
    "\"\"\"\n",
    "messages = [{\"role\": \"user\", \"content\": content}]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-5.1-2025-11-13\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
