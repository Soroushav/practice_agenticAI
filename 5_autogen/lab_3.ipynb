{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b7cb62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from autogen_core import MessageContext, RoutedAgent, SingleThreadedAgentRuntime, AgentId, message_handler\n",
    "from dataclasses import dataclass\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f14b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message:\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "406931bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAgent(RoutedAgent):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"Simple\")\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        return Message(content=f\"This is {self.id.key} | {self.id.type}. You said {message.content} and i disagree!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7e993ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentType(type='simple_agent')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "await SimpleAgent.register(runtime, \"simple_agent\", lambda: SimpleAgent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "022418d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39172d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> This is default | simple_agent. You said Well hi there! and i disagree!\n"
     ]
    }
   ],
   "source": [
    "agent_id = AgentId(\"simple_agent\", \"default\")\n",
    "response = await runtime.send_message(Message(\"Well hi there!\"), agent_id)\n",
    "print(\">>>\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05e913cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "await runtime.stop()\n",
    "await runtime.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beec11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "class MyLLMAgent(RoutedAgent):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"llm_agent\")\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(name=\"llm_Agent\", model_client=model_client)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        print(f\"{self.id.type} received message: {message.content}\")\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], cancellation_token=ctx.cancellation_token)\n",
    "        reply = response.chat_message.content\n",
    "        print(f\"{self.id.type} responded: {reply}\")\n",
    "        return Message(content=reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aab231c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentType(type='llm_agent')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_core import SingleThreadedAgentRuntime\n",
    "\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "await SimpleAgent.register(runtime, \"simple_agent\", lambda: SimpleAgent())\n",
    "await MyLLMAgent.register(runtime, \"llm_agent\", lambda: MyLLMAgent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3e38e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_agent received message: Hi there!!!!\n",
      "llm_agent responded: Hello! How can I assist you today?\n",
      "llm_agent received message: This is default | simple_agent. You said Hello! How can I assist you today? and i disagree!\n",
      "llm_agent responded: I apologize if my response didn't meet your expectations. How can I improve or assist you better?\n"
     ]
    }
   ],
   "source": [
    "runtime.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad6f800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Hello! How can I assist you today?\n",
      ">>> This is default | simple_agent. You said Hello! How can I assist you today? and i disagree!\n",
      ">>> I apologize if my response didn't meet your expectations. How can I improve or assist you better?\n"
     ]
    }
   ],
   "source": [
    "response = await runtime.send_message(Message(\"Hi there!!!!\"), AgentId(\"llm_agent\", \"default\"))\n",
    "print(\">>>\", response.content)\n",
    "response = await runtime.send_message(Message(response.content), AgentId(\"simple_agent\", \"default\"))\n",
    "print(\">>>\", response.content)\n",
    "response = await runtime.send_message(Message(response.content), AgentId(\"llm_agent\", \"default\"))\n",
    "print(\">>>\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03cefc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "await runtime.stop()\n",
    "await runtime.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74cd395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "\n",
    "class Player1Agent(RoutedAgent):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"Player_1\")\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(name=\"Player_1\", model_client=model_client)\n",
    "    \n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], cancellation_token=ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "\n",
    "class Player2Agent(RoutedAgent):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"Player_2\")\n",
    "        model_client = OllamaChatCompletionClient(model=\"llama3.2:latest\")\n",
    "        self._delegate = AssistantAgent(name=\"Player_2\", model_client=model_client)\n",
    "    \n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], cancellation_token=ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a724eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_core import model_context\n",
    "\n",
    "\n",
    "JUDGE = \"You are judging a game of rock, paper, scissors. The players have made these choices:\\n\"\n",
    "\n",
    "class RockPaperScissorsAgent(RoutedAgent):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"Judge\")\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(name=\"Judge\", model_client=model_client)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        instruction = \"You are playing rock, paper, scissors. Respond only with the one word, one of the following: rock, paper, or scissors.\"\n",
    "        message = Message(content=instruction)\n",
    "        inner_1 = AgentId(\"player1\", \"default\")\n",
    "        inner_2 = AgentId(\"player2\", \"default\")\n",
    "        response1 = await self.send_message(message, inner_1)\n",
    "        response2 = await self.send_message(message, inner_2)\n",
    "        result = f\"Player 1: {response1.content}\\nPlayer 2: {response2.content}\\n\"\n",
    "        judgement = f\"{JUDGE}{result}Who wins?\"\n",
    "        message = TextMessage(content=judgement, source=\"user\")\n",
    "        response = await self._delegate.on_messages([message], ctx.cancellation_token)\n",
    "        return Message(content=result + response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99fea374",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = SingleThreadedAgentRuntime()\n",
    "await Player1Agent.register(runtime, \"player1\", lambda: Player1Agent())\n",
    "await Player2Agent.register(runtime, \"player2\", lambda: Player2Agent())\n",
    "\n",
    "await RockPaperScissorsAgent.register(runtime, \"rock_paper_scissors\", lambda: RockPaperScissorsAgent())\n",
    "\n",
    "runtime.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46dfcd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1: rock\n",
      "Player 2: scissors\n",
      "Player 1 wins. Rock beats scissors. TERMINATE\n"
     ]
    }
   ],
   "source": [
    "agent_id = AgentId(\"rock_paper_scissors\", \"default\")\n",
    "message = Message(content=\"go\")\n",
    "response = await runtime.send_message(message, agent_id)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bd3afb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1: scissors\n",
      "Player 2: paper\n",
      "Player 1 wins. Scissors beats paper. TERMINATE\n"
     ]
    }
   ],
   "source": [
    "agent_id = AgentId(\"rock_paper_scissors\", \"default\")\n",
    "message = Message(content=\"go\")\n",
    "response = await runtime.send_message(message, agent_id)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aad0731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "await runtime.stop()\n",
    "await runtime.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c229cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
